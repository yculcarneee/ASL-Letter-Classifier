{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "from torch import optim, cuda\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "from torchsummary import summary\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from timeit import default_timer as timer\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import random\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_on_gpu = cuda.is_available()\n",
    "print(f'Train on gpu: {train_on_gpu}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_char_map = {0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E', 5: 'F', 6: 'G', 7: 'H', 8: 'I', 9: 'J', 10: 'K', 11: 'L', 12: 'M', 13: 'N', 14: 'O', 15: 'P', 16: 'Q', 17: 'R', 18: 'S', 19: 'T', 20: 'U', 21: 'V', 22: 'W', 23: 'X', 24: 'Y', 25: 'Z', 26: 'del', 27: 'nothing', 28: 'space'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "dataset_1_dir = '../input/asl-alphabet/asl_alphabet_train/asl_alphabet_train' #Link: https://www.kaggle.com/grassknoted/asl-alphabet\n",
    "dataset_2_dir = '../input/aslalphabettestmodified/asl-alphabet-test' #Link: https://www.kaggle.com/yashudaykulkarni/aslalphabettestmodified\n",
    "\n",
    "img_dir = '../input/asl-alphabet/asl_alphabet_test/asl_alphabet_test/'\n",
    "\n",
    "save_file_name_1 = 'vgg_cur_model_1.pt'\n",
    "save_file_name_2 = 'vgg_cur_model_2.pt'\n",
    "\n",
    "batch_size = 16\n",
    "lr = 0.001\n",
    "momentum = 0.9\n",
    "epoch_stop_condition = 5\n",
    "n_epochs = 5\n",
    "\n",
    "dataset_1_length = 87000\n",
    "dataset_2_length = 870\n",
    "\n",
    "n_classes = 29\n",
    "\n",
    "train_split_ratio = 0.5\n",
    "val_split_ratio = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transforms = {\n",
    "    'train':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((150, 150)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])  \n",
    "    ]),\n",
    "    'val':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((150, 150)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((150, 150)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 6)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 5)\n",
    "        self.fc1 = nn.Linear(64 * 15 * 15, 480)\n",
    "        self.fc2 = nn.Linear(480, 240)\n",
    "        self.fc3 = nn.Linear(240, 29)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 64 * 15 * 15)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader_lengths(dataset_length, train_split_ratio, val_split_ratio):\n",
    "    train_split = int(np.floor(train_split_ratio * dataset_length))\n",
    "    val_split = int(np.floor(val_split_ratio * dataset_length))\n",
    "    \n",
    "    train_dataloader_length = train_split\n",
    "    val_dataloader_length = val_split\n",
    "    test_dataloader_length = dataset_length-(train_dataloader_length + val_dataloader_length)\n",
    "    \n",
    "    return train_dataloader_length, test_dataloader_length, val_dataloader_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset_length, train_split_length, val_split_length, dataset):\n",
    "    indices = list(range(dataset_length))\n",
    "        \n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    train_indices = indices[:train_split_length]\n",
    "    val_indices = indices[train_split_length:train_split_length+val_split_length]\n",
    "    test_indices = indices[train_split_length+val_split_length:] \n",
    "    \n",
    "    train_indices_df = pd.DataFrame(train_indices)\n",
    "    train_indices_df.to_csv('train_indices_' + str(dataset) + '_vals.csv', index=False)\n",
    "    \n",
    "    test_indices_df = pd.DataFrame(test_indices)\n",
    "    test_indices_df.to_csv('test_indices_' + str(dataset) + '_vals.csv', index=False)\n",
    "    \n",
    "    val_indices_df = pd.DataFrame(val_indices)\n",
    "    val_indices_df.to_csv('val_indices_' + str(dataset) + '_vals.csv', index=False)\n",
    "\n",
    "    return train_indices, test_indices, val_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ImageFolder(dataset_dir):\n",
    "    data = {\n",
    "        'train': datasets.ImageFolder(root=dataset_dir, transform=image_transforms['train']),\n",
    "        'val': datasets.ImageFolder(root=dataset_dir, transform=image_transforms['val']),\n",
    "        'test': datasets.ImageFolder(root=dataset_dir, transform=image_transforms['test']),\n",
    "    }\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sampler(train_indices, test_indices, val_indices):\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    test_sampler = SubsetRandomSampler(test_indices)\n",
    "    val_sampler = SubsetRandomSampler(val_indices)\n",
    "    \n",
    "    return train_sampler, test_sampler, val_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_DataLoader(data, train_sampler, test_sampler, val_sampler):\n",
    "    dataloader = {\n",
    "        'train': DataLoader(data['train'], batch_size=batch_size, sampler=train_sampler),\n",
    "        'val': DataLoader(data['val'], batch_size=batch_size, sampler=val_sampler),\n",
    "        'test': DataLoader(data['test'], batch_size=batch_size, sampler=test_sampler),\n",
    "    }\n",
    "    \n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Net()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "    if train_on_gpu:\n",
    "        model = model.to('cuda')\n",
    "    return model, criterion, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model):\n",
    "    torch.save(model.state_dict(), save_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model):\n",
    "    model.load_state_dict(torch.load(save_file_name))\n",
    "    model.optimizer = optimizer\n",
    "    if train_on_gpu:\n",
    "        model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_dataloader, train_dataloader_length, val_dataloader, val_dataloader_length, criterion, optimizer, epoch_stop_condition, n_epochs):\n",
    "    n_epochs_no_improvement = 0\n",
    "    val_loss_min = np.Inf\n",
    "    \n",
    "    history = []\n",
    "    \n",
    "    try:\n",
    "        print(f'Model has been trained for: {model.epochs} epochs.\\n')\n",
    "    except:\n",
    "        model.epochs = 0\n",
    "        print(f'Starting Training from Scratch.\\n')\n",
    "    \n",
    "    begin_time = timer()\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        cur_epoch_train_loss = 0.0\n",
    "        cur_epoch_val_loss = 0.0\n",
    "        \n",
    "        cur_epoch_train_acc = 0\n",
    "        cur_epoch_val_acc = 0\n",
    "        \n",
    "        model.train()\n",
    "        cur_epoch_start_time = timer()\n",
    "        \n",
    "        for step, (features, labels) in enumerate(train_dataloader):\n",
    "            if train_on_gpu:\n",
    "                features = features.cuda()\n",
    "                labels = labels.cuda()\n",
    "                \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(features)\n",
    "\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            cur_epoch_train_loss += loss.item() * features.size(0)\n",
    "\n",
    "            _, pred = torch.max(output, dim=1)\n",
    "            cur_epoch_train_acc += torch.sum(pred == labels.data)\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "            del features, labels, output, pred\n",
    "\n",
    "            print(f'Epoch: {epoch}\\t{100 * (step + 1) / len(train_dataloader):.2f}% complete. {timer() - cur_epoch_start_time:.2f} seconds elapsed in epoch.',end='\\r')\n",
    "                    \n",
    "        \n",
    "        model.epochs += 1\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            \n",
    "            for features, labels in val_dataloader:\n",
    "                if train_on_gpu:\n",
    "                    features = features.cuda()\n",
    "                    labels = labels.cuda()\n",
    "\n",
    "                output = model(features)\n",
    "\n",
    "                loss = criterion(output, labels)\n",
    "\n",
    "                cur_epoch_val_loss += loss.item() * features.size(0)\n",
    "\n",
    "                _, pred = torch.max(output, dim=1)\n",
    "                cur_epoch_val_acc += torch.sum(pred == labels.data)\n",
    "\n",
    "                torch.cuda.empty_cache()\n",
    "                del features, labels, output, pred\n",
    "            \n",
    "            cur_epoch_train_loss = cur_epoch_train_loss / train_dataloader_length\n",
    "            cur_epoch_val_loss = cur_epoch_val_loss / val_dataloader_length\n",
    "            \n",
    "            cur_epoch_train_acc = cur_epoch_train_acc.double() / train_dataloader_length\n",
    "            cur_epoch_val_acc = cur_epoch_val_acc.double() / val_dataloader_length\n",
    "            \n",
    "            history.append([cur_epoch_train_loss, cur_epoch_val_loss, cur_epoch_train_acc, cur_epoch_val_acc])\n",
    "            \n",
    "            print(f'\\nEpoch: {epoch} \\tTraining Loss: {cur_epoch_train_loss:.4f} \\tValidation Loss: {cur_epoch_val_loss:.4f}')\n",
    "            print(f'\\t\\tTraining Accuracy: {100 * cur_epoch_train_acc:.2f}%\\t Validation Accuracy: {100 * cur_epoch_val_acc:.2f}%')\n",
    "            \n",
    "            if cur_epoch_val_loss < val_loss_min:\n",
    "                torch.save(model.state_dict(), save_file_name)\n",
    "                \n",
    "                n_epochs_no_improvement = 0\n",
    "                \n",
    "                val_loss_min = cur_epoch_val_loss\n",
    "                best_val_acc = cur_epoch_val_acc\n",
    "                best_epoch = epoch\n",
    "                \n",
    "            else:\n",
    "                n_epochs_no_improvement += 1\n",
    "                \n",
    "                if n_epochs_no_improvement >= epoch_stop_condition:\n",
    "                    print(f'\\nEarly Stopping! Total epochs: {epoch}. Best epoch: {best_epoch} with loss: {val_loss_min:.2f} and acc: {100 * best_val_acc:.2f}%')\n",
    "                    \n",
    "                    total_time = timer() - begin_time\n",
    "                    print(f'{total_time:.2f} total seconds elapsed. {total_time / (epoch+1):.2f} seconds per epoch.')    \n",
    "                \n",
    "                    model.load_state_dict(torch.load(save_file_name))\n",
    "                    model.optimizer = optimizer\n",
    "                    \n",
    "                    history = pd.DataFrame(history, columns=['train_loss', 'val_loss', 'train_acc','val_acc'])\n",
    "                    \n",
    "                    return model, history\n",
    "    \n",
    "    model.optimizer = optimizer\n",
    "    \n",
    "    total_time = timer() - begin_time\n",
    "    \n",
    "    print(f'\\nBest epoch: {best_epoch} with loss: {val_loss_min:.2f} and acc: {100 * best_val_acc:.2f}%')\n",
    "    print(f'{total_time:.2f} total seconds elapsed. {total_time / (epoch+1):.2f} seconds per epoch.')    \n",
    "              \n",
    "    history = pd.DataFrame(history, columns=['train_loss', 'val_loss', 'train_acc','val_acc'])\n",
    "                    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_freq_class_dataloader(dataloader):\n",
    "    freq_list = np.zeros(29)\n",
    "\n",
    "    for step, (images, labels) in enumerate(dataloader):\n",
    "        for label in labels:\n",
    "            freq_list[label] += 1\n",
    "        del images, labels\n",
    "\n",
    "    return freq_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(test_dataloader, test_dataloader_length, freq_list):\n",
    "    test_loss = 0.0\n",
    "    test_acc = 0.0\n",
    "    \n",
    "    acc_every_class = np.zeros(29)\n",
    "        \n",
    "    for features, labels in test_dataloader:\n",
    "        model.eval()\n",
    "        \n",
    "        if train_on_gpu:\n",
    "            features = features.cuda()\n",
    "            labels = labels.cuda()\n",
    "            \n",
    "        output = model(features)\n",
    "        \n",
    "        loss = criterion(output, labels)\n",
    "        \n",
    "        test_loss += loss.item() * features.size(0)\n",
    "        \n",
    "        _, pred = torch.max(output, dim=1)\n",
    "        test_acc += torch.sum(pred == labels.data)\n",
    "        \n",
    "        for i, (p, label) in enumerate(zip(pred, labels)):\n",
    "            acc_every_class[label] += (pred[i] == labels[i])\n",
    "            \n",
    "        torch.cuda.empty_cache()\n",
    "        del features, labels, output, pred\n",
    "        \n",
    "    test_acc = test_acc.double() / test_dataloader_length\n",
    "    test_loss = test_loss / test_dataloader_length\n",
    "    \n",
    "    for i in range(len(acc_every_class)):\n",
    "        acc_every_class[i] = acc_every_class[i] / freq_list[i]\n",
    "        \n",
    "    return test_acc, test_loss, acc_every_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader_1_length, test_dataloader_1_length, val_dataloader_1_length = dataloader_lengths(dataset_1_length, train_split_ratio, val_split_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader_2_length, test_dataloader_2_length, val_dataloader_2_length = dataloader_lengths(dataset_2_length, train_split_ratio, val_split_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices_1, test_indices_1, val_indices_1 = split_dataset(dataset_1_length, train_dataloader_1_length, val_dataloader_1_length, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices_2, test_indices_2, val_indices_2 = split_dataset(dataset_2_length, train_dataloader_2_length, val_dataloader_2_length, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler_1, test_sampler_1, val_sampler_1 = create_sampler(train_indices_1, test_indices_1, val_indices_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler_2, test_sampler_2, val_sampler_2 = create_sampler(train_indices_2, test_indices_2, val_indices_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = create_ImageFolder(dataset_1_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2 = create_ImageFolder(dataset_2_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_1 = create_DataLoader(data_1, train_sampler_1, test_sampler_1, val_sampler_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_2 = create_DataLoader(data_2, train_sampler_2, test_sampler_2, val_sampler_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_iter = iter(dataloader_1['train'])\n",
    "features, labels = next(dummy_iter)\n",
    "features.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_iter = iter(dataloader_2['train'])\n",
    "features, labels = next(dummy_iter)\n",
    "features.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, criterion, optimizer = get_model(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, history = train_model(model, dataloader_1['train'], train_dataloader_1_length, dataloader_1['val'], val_dataloader_1_length, criterion, optimizer, epoch_stop_condition, n_epochs, save_file_name_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.to_csv(r'model_training_stats_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "for c in ['train_loss', 'val_loss']:\n",
    "    plt.plot(history[c], label=c)\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average Cross Entropy Loss')\n",
    "plt.title('Training and Validation Losses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "for c in ['train_acc', 'val_acc']:\n",
    "    plt.plot(100 * history[c], label=c)\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average Accuracy')\n",
    "plt.title('Training and Validation Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_list_test_1 = generate_freq_class_dataloader(dataloader_1['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc_1, test_loss_1, acc_every_class_1 = eval_model(dataloader_1['test'], test_dataloader_1_length, freq_list_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_acc_1.item() * 100, test_loss_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acc_every_class_1 * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_list_test_2 = generate_freq_class_dataloader(dataloader_2['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc_2, test_loss_2, acc_every_class_2 = eval_model(dataloader_2['test'], test_dataloader_2_length, freq_list_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_acc_2.item() * 100, test_loss_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acc_every_class_2 * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, history = train_model(model, dataloader_2['train'], train_dataloader_2_length, dataloader_2['val'], val_dataloader_2_length, criterion, optimizer, epoch_stop_condition, n_epochs, save_file_name_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.to_csv(r'model_training_stats_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "for c in ['train_loss', 'val_loss']:\n",
    "    plt.plot(history[c], label=c)\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average Cross Entropy Loss')\n",
    "plt.title('Training and Validation Losses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "for c in ['train_acc', 'val_acc']:\n",
    "    plt.plot(100 * history[c], label=c)\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average Accuracy')\n",
    "plt.title('Training and Validation Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc_2, test_loss_2, acc_every_class_2 = eval_model(dataloader_2['test'], test_dataloader_2_length, freq_list_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_acc_2.item() * 100, test_loss_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acc_every_class_2 * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
